{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f56b590dfd0>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f56b590dcf8>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x7f56b590def0>)\n"
     ]
    }
   ],
   "source": [
    "print(mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = mnist.train.num_examples # 55,000\n",
    "n_validation = mnist.validation.num_examples # 5000\n",
    "n_test = mnist.test.num_examples # 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 784   # input layer (28x28 pixels)\n",
    "n_hidden1 = 512 # 1st hidden layer\n",
    "n_hidden2 = 256 # 2nd hidden layer\n",
    "n_hidden3 = 128 # 3rd hidden layer\n",
    "n_output = 10   # output layer (0-9 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4   \n",
    "n_iterations = 3000\n",
    "batch_size = 128\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", [None, n_input])   #Tensor to create the perceptrons of input \n",
    "Y = tf.placeholder(\"float\", [None, n_output])  #Tensor to create the perceptrons of output\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "'w1': tf.Variable(tf.truncated_normal([n_input, n_hidden1],stddev=0.1)), \n",
    "'w2': tf.Variable(tf.truncated_normal([n_hidden1, n_hidden2],stddev=0.1)),\n",
    "'w3': tf.Variable(tf.truncated_normal([n_hidden2, n_hidden3],stddev=0.1)),\n",
    "'out': tf.Variable(tf.truncated_normal([n_hidden3, n_output],stddev=0.1)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = {\n",
    "'b1': tf.Variable(tf.constant(0.1, shape=[n_hidden1])),\n",
    "'b2': tf.Variable(tf.constant(0.1, shape=[n_hidden2])),\n",
    "'b3': tf.Variable(tf.constant(0.1, shape=[n_hidden3])),\n",
    "'out': tf.Variable(tf.constant(0.1, shape=[n_output]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = tf.add(tf.matmul(X, weights['w1']), biases['b1'])\n",
    "layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n",
    "layer_3 = tf.add(tf.matmul(layer_2, weights['w3']), biases['b3'])\n",
    "layer_drop = tf.nn.dropout(layer_3, keep_prob)\n",
    "output_layer = tf.matmul(layer_3, weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=Y, logits=output_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(output_layer, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 1 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 2 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 3 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 4 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 5 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 6 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 7 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 8 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 9 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 10 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 11 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 12 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 13 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 14 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 15 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 16 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 17 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 18 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 19 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 20 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 21 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 22 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 23 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 24 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 25 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 26 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 27 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 28 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 29 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 30 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 31 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 32 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 33 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 34 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 35 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 36 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 37 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 38 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 39 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 40 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 41 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 42 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 43 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 44 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 45 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 46 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 47 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 48 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 49 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 50 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 51 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 52 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 53 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 54 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 55 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 56 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 57 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 58 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 59 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 60 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 61 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 62 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 63 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 64 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 65 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 66 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 67 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 68 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 69 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 70 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 71 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 72 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 73 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 74 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 75 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 76 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 77 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 78 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 79 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 80 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 81 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 82 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 83 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 84 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 85 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 86 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 87 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 88 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 89 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 90 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 91 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 92 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 93 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 94 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 95 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 96 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 97 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 98 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 99 \t| Loss = 0.17836732 \t| Accuracy = 0.9375\n",
      "Iteration 100 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 101 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 102 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 103 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 104 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 105 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 106 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 107 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 108 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 109 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 110 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 111 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 112 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 113 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 114 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 115 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 116 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 117 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 118 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 119 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 120 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 121 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 122 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 123 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 124 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 125 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 126 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 127 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 128 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 129 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 130 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 131 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 132 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 133 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 134 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 135 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 136 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 137 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 138 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 139 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 140 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 141 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 142 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 143 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 144 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 145 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 146 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 147 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 148 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 149 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 150 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 151 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 152 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 153 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 154 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 155 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 156 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 157 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 158 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 159 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 160 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 161 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 162 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 163 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 164 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 165 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 166 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 167 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 168 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 169 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 170 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 171 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 172 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 173 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 174 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 175 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 176 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 177 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 178 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 179 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 180 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 181 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 182 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 183 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 184 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 185 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 186 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 187 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 188 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 189 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 190 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 191 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 192 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 193 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 194 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 195 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 196 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 197 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 198 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 199 \t| Loss = 0.26215592 \t| Accuracy = 0.9140625\n",
      "Iteration 200 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 201 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 202 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 203 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 204 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 205 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 206 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 207 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 208 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 209 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 210 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 211 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 212 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 213 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 214 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 215 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 216 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 217 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 218 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 219 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 220 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 221 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 222 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 223 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 224 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 225 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 226 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 227 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 228 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 229 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 230 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 231 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 232 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 233 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 234 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 235 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 236 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 237 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 238 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 239 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 240 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 241 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 242 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 243 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 244 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 245 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 246 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 247 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 248 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 249 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 250 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 251 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 252 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 253 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 254 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 255 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 256 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 257 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 258 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 259 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 260 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 261 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 262 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 263 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 264 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 265 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 266 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 267 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 268 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 269 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 270 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 271 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 272 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 273 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 274 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 275 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 276 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 277 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 278 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 279 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 280 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 281 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 282 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 283 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 284 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 285 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 286 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 287 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 288 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 289 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 290 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 291 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 292 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 293 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 294 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 295 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 296 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 297 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 298 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 299 \t| Loss = 0.24069859 \t| Accuracy = 0.9375\n",
      "Iteration 300 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 301 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 302 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 303 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 304 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 305 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 306 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 307 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 308 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 309 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 310 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 311 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 312 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 313 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 314 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 315 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 316 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 317 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 318 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 319 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 320 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 321 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 322 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 323 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 324 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 325 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 326 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 327 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 328 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 329 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 330 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 331 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 332 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 333 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 334 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 335 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 336 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 337 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 338 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 339 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 340 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 341 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 342 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 343 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 344 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 345 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 346 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 347 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 348 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 349 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 350 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 351 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 352 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 353 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 354 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 355 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 356 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 357 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 358 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 359 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 360 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 361 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 362 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 363 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 364 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 365 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 366 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 367 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 368 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 369 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 370 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 371 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 372 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 373 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 374 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 375 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 376 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 377 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 378 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 379 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 380 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 381 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 382 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 383 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 384 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 385 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 386 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 387 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 388 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 389 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 390 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 391 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 392 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 393 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 394 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 395 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 396 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 397 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 398 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 399 \t| Loss = 0.22932673 \t| Accuracy = 0.9296875\n",
      "Iteration 400 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 401 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 402 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 403 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 404 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 405 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 406 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 407 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 408 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 409 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 410 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 411 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 412 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 413 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 414 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 415 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 416 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 417 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 418 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 419 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 420 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 421 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 422 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 423 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 424 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 425 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 426 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 427 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 428 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 429 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 430 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 431 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 432 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 433 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 434 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 435 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 436 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 437 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 438 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 439 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 440 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 441 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 442 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 443 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 444 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 445 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 446 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 447 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 448 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 449 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 450 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 451 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 452 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 453 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 454 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 455 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 456 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 457 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 458 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 459 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 460 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 461 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 462 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 463 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 464 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 465 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 466 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 467 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 468 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 469 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 470 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 471 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 472 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 473 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 474 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 475 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 476 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 477 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 478 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 479 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 480 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 481 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 482 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 483 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 484 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 485 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 486 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 487 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 488 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 489 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 490 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 491 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 492 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 493 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 494 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 495 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 496 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 497 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 498 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 499 \t| Loss = 0.19605514 \t| Accuracy = 0.9375\n",
      "Iteration 500 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 501 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 502 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 503 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 504 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 505 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 506 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 507 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 508 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 509 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 510 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 511 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 512 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 513 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 514 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 515 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 516 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 517 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 518 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 519 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 520 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 521 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 522 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 523 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 524 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 525 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 526 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 527 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 528 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 529 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 530 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 531 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 532 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 533 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 534 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 535 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 536 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 537 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 538 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 539 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 540 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 541 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 542 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 543 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 544 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 545 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 546 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 547 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 548 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 549 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 550 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 551 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 552 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 553 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 554 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 555 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 556 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 557 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 558 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 559 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 560 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 561 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 562 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 563 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 564 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 565 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 566 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 567 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 568 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 569 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 570 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 571 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 572 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 573 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 574 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 575 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 576 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 577 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 578 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 579 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 580 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 581 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 582 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 583 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 584 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 585 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 586 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 587 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 588 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 589 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 590 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 591 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 592 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 593 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 594 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 595 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 596 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 597 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 598 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 599 \t| Loss = 0.2050902 \t| Accuracy = 0.9375\n",
      "Iteration 600 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 601 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 602 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 603 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 604 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 605 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 606 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 607 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 608 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 609 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 610 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 611 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 612 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 613 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 614 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 615 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 616 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 617 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 618 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 619 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 620 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 621 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 622 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 623 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 624 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 625 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 626 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 627 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 628 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 629 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 630 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 631 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 632 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 633 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 634 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 635 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 636 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 637 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 638 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 639 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 640 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 641 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 642 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 643 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 644 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 645 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 646 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 647 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 648 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 649 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 650 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 651 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 652 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 653 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 654 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 655 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 656 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 657 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 658 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 659 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 660 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 661 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 662 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 663 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 664 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 665 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 666 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 667 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 668 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 669 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 670 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 671 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 672 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 673 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 674 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 675 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 676 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 677 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 678 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 679 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 680 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 681 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 682 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 683 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 684 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 685 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 686 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 687 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 688 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 689 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 690 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 691 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 692 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 693 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 694 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 695 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 696 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 697 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 698 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 699 \t| Loss = 0.2539478 \t| Accuracy = 0.9453125\n",
      "Iteration 700 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 701 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 702 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 703 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 704 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 705 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 706 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 707 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 708 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 709 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 710 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 711 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 712 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 713 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 714 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 715 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 716 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 717 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 718 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 719 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 720 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 721 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 722 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 723 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 724 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 725 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 726 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 727 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 728 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 729 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 730 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 731 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 732 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 733 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 734 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 735 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 736 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 737 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 738 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 739 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 740 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 741 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 742 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 743 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 744 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 745 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 746 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 747 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 748 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 749 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 750 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 751 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 752 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 753 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 754 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 755 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 756 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 757 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 758 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 759 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 760 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 761 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 762 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 763 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 764 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 765 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 766 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 767 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 768 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 769 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 770 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 771 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 772 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 773 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 774 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 775 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 776 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 777 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 778 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 779 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 780 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 781 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 782 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 783 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 784 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 785 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 786 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 787 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 788 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 789 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 790 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 791 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 792 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 793 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 794 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 795 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 796 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 797 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 798 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 799 \t| Loss = 0.21039209 \t| Accuracy = 0.9375\n",
      "Iteration 800 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 801 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 802 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 803 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 804 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 805 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 806 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 807 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 808 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 809 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 810 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 811 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 812 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 813 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 814 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 815 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 816 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 817 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 818 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 819 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 820 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 821 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 822 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 823 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 824 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 825 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 826 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 827 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 828 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 829 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 830 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 831 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 832 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 833 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 834 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 835 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 836 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 837 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 838 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 839 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 840 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 841 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 842 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 843 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 844 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 845 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 846 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 847 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 848 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 849 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 850 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 851 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 852 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 853 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 854 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 855 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 856 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 857 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 858 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 859 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 860 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 861 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 862 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 863 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 864 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 865 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 866 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 867 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 868 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 869 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 870 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 871 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 872 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 873 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 874 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 875 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 876 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 877 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 878 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 879 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 880 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 881 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 882 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 883 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 884 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 885 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 886 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 887 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 888 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 889 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 890 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 891 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 892 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 893 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 894 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 895 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 896 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 897 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 898 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 899 \t| Loss = 0.2592255 \t| Accuracy = 0.9453125\n",
      "Iteration 900 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 901 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 902 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 903 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 904 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 905 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 906 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 907 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 908 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 909 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 910 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 911 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 912 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 913 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 914 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 915 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 916 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 917 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 918 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 919 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 920 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 921 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 922 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 923 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 924 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 925 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 926 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 927 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 928 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 929 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 930 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 931 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 932 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 933 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 934 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 935 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 936 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 937 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 938 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 939 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 940 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 941 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 942 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 943 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 944 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 945 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 946 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 947 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 948 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 949 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 950 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 951 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 952 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 953 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 954 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 955 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 956 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 957 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 958 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 959 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 960 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 961 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 962 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 963 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 964 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 965 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 966 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 967 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 968 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 969 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 970 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 971 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 972 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 973 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 974 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 975 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 976 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 977 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 978 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 979 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 980 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 981 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 982 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 983 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 984 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 985 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 986 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 987 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 988 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 989 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 990 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 991 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 992 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 993 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 994 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 995 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 996 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 997 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 998 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 999 \t| Loss = 0.3591176 \t| Accuracy = 0.90625\n",
      "Iteration 1000 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1001 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1002 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1003 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1004 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1005 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1006 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1007 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1008 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1009 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1010 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1011 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1012 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1013 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1014 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1015 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1016 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1017 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1018 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1019 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1020 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1021 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1022 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1023 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1024 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1025 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1026 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1027 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1028 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1029 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1030 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1031 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1032 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1033 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1034 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1035 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1036 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1037 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1038 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1039 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1040 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1041 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1042 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1043 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1044 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1045 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1046 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1047 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1048 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1049 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1050 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1051 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1052 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1053 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1054 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1055 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1056 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1057 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1058 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1059 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1060 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1061 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1062 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1063 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1064 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1065 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1066 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1067 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1068 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1069 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1070 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1071 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1072 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1073 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1074 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1075 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1076 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1077 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1078 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1079 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1080 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1081 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1082 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1083 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1084 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1085 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1086 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1087 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1088 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1089 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1090 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1091 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1092 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1093 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1094 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1095 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1096 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1097 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1098 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1099 \t| Loss = 0.16204092 \t| Accuracy = 0.96875\n",
      "Iteration 1100 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1101 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1102 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1103 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1104 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1105 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1106 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1107 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1108 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1109 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1110 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1111 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1112 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1113 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1114 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1115 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1116 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1117 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1118 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1119 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1120 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1121 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1122 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1123 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1124 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1125 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1126 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1127 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1128 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1129 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1130 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1131 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1132 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1133 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1134 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1135 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1136 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1137 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1138 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1139 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1140 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1141 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1142 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1143 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1144 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1145 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1146 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1147 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1148 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1149 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1150 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1151 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1152 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1153 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1154 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1155 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1156 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1157 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1158 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1159 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1160 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1161 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1162 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1163 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1164 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1165 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1166 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1167 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1168 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1169 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1170 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1171 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1172 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1173 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1174 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1175 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1176 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1177 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1178 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1179 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1180 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1181 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1182 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1183 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1184 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1185 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1186 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1187 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1188 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1189 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1190 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1191 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1192 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1193 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1194 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1195 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1196 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1197 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1198 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1199 \t| Loss = 0.20796186 \t| Accuracy = 0.9453125\n",
      "Iteration 1200 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1201 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1202 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1203 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1204 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1205 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1206 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1207 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1208 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1209 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1210 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1211 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1212 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1213 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1214 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1215 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1216 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1217 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1218 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1219 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1220 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1221 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1222 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1223 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1224 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1225 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1226 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1227 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1228 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1229 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1230 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1231 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1232 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1233 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1234 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1235 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1236 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1237 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1238 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1239 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1240 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1241 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1242 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1243 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1244 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1245 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1246 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1247 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1248 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1249 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1250 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1251 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1252 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1253 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1254 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1255 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1256 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1257 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1258 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1259 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1260 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1261 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1262 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1263 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1264 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1265 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1266 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1267 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1268 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1269 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1270 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1271 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1272 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1273 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1274 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1275 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1276 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1277 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1278 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1279 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1280 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1281 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1282 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1283 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1284 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1285 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1286 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1287 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1288 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1289 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1290 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1291 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1292 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1293 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1294 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1295 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1296 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1297 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1298 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1299 \t| Loss = 0.21272758 \t| Accuracy = 0.9140625\n",
      "Iteration 1300 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1301 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1302 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1303 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1304 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1305 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1306 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1307 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1308 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1309 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1310 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1311 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1312 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1313 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1314 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1315 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1316 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1317 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1318 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1319 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1320 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1321 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1322 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1323 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1324 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1325 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1326 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1327 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1328 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1329 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1330 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1331 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1332 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1333 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1334 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1335 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1336 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1337 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1338 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1339 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1340 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1341 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1342 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1343 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1344 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1345 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1346 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1347 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1348 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1349 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1350 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1351 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1352 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1353 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1354 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1355 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1356 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1357 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1358 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1359 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1360 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1361 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1362 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1363 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1364 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1365 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1366 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1367 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1368 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1369 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1370 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1371 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1372 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1373 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1374 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1375 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1376 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1377 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1378 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1379 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1380 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1381 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1382 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1383 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1384 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1385 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1386 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1387 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1388 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1389 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1390 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1391 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1392 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1393 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1394 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1395 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1396 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1397 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1398 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1399 \t| Loss = 0.35960606 \t| Accuracy = 0.8984375\n",
      "Iteration 1400 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1401 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1402 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1403 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1404 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1405 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1406 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1407 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1408 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1409 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1410 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1411 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1412 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1413 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1414 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1415 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1416 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1417 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1418 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1419 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1420 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1421 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1422 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1423 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1424 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1425 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1426 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1427 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1428 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1429 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1430 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1431 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1432 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1433 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1434 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1435 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1436 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1437 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1438 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1439 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1440 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1441 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1442 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1443 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1444 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1445 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1446 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1447 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1448 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1449 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1450 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1451 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1452 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1453 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1454 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1455 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1456 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1457 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1458 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1459 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1460 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1461 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1462 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1463 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1464 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1465 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1466 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1467 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1468 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1469 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1470 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1471 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1472 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1473 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1474 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1475 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1476 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1477 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1478 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1479 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1480 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1481 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1482 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1483 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1484 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1485 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1486 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1487 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1488 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1489 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1490 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1491 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1492 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1493 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1494 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1495 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1496 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1497 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1498 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1499 \t| Loss = 0.20919217 \t| Accuracy = 0.96875\n",
      "Iteration 1500 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1501 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1502 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1503 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1504 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1505 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1506 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1507 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1508 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1509 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1510 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1511 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1512 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1513 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1514 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1515 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1516 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1517 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1518 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1519 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1520 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1521 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1522 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1523 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1524 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1525 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1526 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1527 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1528 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1529 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1530 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1531 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1532 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1533 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1534 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1535 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1536 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1537 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1538 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1539 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1540 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1541 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1542 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1543 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1544 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1545 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1546 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1547 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1548 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1549 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1550 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1551 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1552 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1553 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1554 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1555 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1556 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1557 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1558 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1559 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1560 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1561 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1562 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1563 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1564 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1565 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1566 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1567 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1568 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1569 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1570 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1571 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1572 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1573 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1574 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1575 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1576 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1577 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1578 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1579 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1580 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1581 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1582 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1583 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1584 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1585 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1586 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1587 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1588 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1589 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1590 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1591 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1592 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1593 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1594 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1595 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1596 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1597 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1598 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1599 \t| Loss = 0.28597867 \t| Accuracy = 0.890625\n",
      "Iteration 1600 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1601 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1602 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1603 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1604 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1605 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1606 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1607 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1608 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1609 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1610 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1611 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1612 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1613 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1614 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1615 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1616 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1617 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1618 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1619 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1620 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1621 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1622 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1623 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1624 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1625 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1626 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1627 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1628 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1629 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1630 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1631 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1632 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1633 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1634 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1635 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1636 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1637 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1638 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1639 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1640 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1641 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1642 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1643 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1644 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1645 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1646 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1647 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1648 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1649 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1650 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1651 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1652 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1653 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1654 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1655 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1656 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1657 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1658 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1659 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1660 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1661 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1662 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1663 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1664 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1665 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1666 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1667 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1668 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1669 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1670 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1671 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1672 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1673 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1674 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1675 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1676 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1677 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1678 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1679 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1680 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1681 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1682 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1683 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1684 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1685 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1686 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1687 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1688 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1689 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1690 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1691 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1692 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1693 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1694 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1695 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1696 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1697 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1698 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1699 \t| Loss = 0.20560196 \t| Accuracy = 0.9296875\n",
      "Iteration 1700 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1701 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1702 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1703 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1704 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1705 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1706 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1707 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1708 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1709 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1710 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1711 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1712 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1713 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1714 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1715 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1716 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1717 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1718 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1719 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1720 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1721 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1722 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1723 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1724 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1725 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1726 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1727 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1728 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1729 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1730 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1731 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1732 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1733 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1734 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1735 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1736 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1737 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1738 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1739 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1740 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1741 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1742 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1743 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1744 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1745 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1746 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1747 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1748 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1749 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1750 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1751 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1752 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1753 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1754 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1755 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1756 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1757 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1758 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1759 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1760 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1761 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1762 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1763 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1764 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1765 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1766 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1767 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1768 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1769 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1770 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1771 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1772 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1773 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1774 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1775 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1776 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1777 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1778 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1779 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1780 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1781 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1782 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1783 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1784 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1785 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1786 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1787 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1788 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1789 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1790 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1791 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1792 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1793 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1794 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1795 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1796 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1797 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1798 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1799 \t| Loss = 0.2958761 \t| Accuracy = 0.8828125\n",
      "Iteration 1800 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1801 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1802 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1803 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1804 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1805 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1806 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1807 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1808 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1809 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1810 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1811 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1812 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1813 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1814 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1815 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1816 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1817 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1818 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1819 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1820 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1821 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1822 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1823 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1824 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1825 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1826 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1827 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1828 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1829 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1830 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1831 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1832 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1833 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1834 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1835 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1836 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1837 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1838 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1839 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1840 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1841 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1842 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1843 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1844 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1845 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1846 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1847 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1848 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1849 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1850 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1851 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1852 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1853 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1854 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1855 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1856 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1857 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1858 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1859 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1860 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1861 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1862 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1863 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1864 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1865 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1866 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1867 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1868 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1869 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1870 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1871 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1872 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1873 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1874 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1875 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1876 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1877 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1878 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1879 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1880 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1881 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1882 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1883 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1884 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1885 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1886 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1887 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1888 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1889 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1890 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1891 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1892 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1893 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1894 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1895 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1896 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1897 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1898 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1899 \t| Loss = 0.32088113 \t| Accuracy = 0.9296875\n",
      "Iteration 1900 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1901 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1902 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1903 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1904 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1905 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1906 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1907 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1908 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1909 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1910 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1911 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1912 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1913 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1914 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1915 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1916 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1917 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1918 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1919 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1920 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1921 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1922 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1923 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1924 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1925 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1926 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1927 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1928 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1929 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1930 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1931 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1932 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1933 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1934 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1935 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1936 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1937 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1938 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1939 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1940 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1941 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1942 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1943 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1944 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1945 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1946 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1947 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1948 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1949 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1950 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1951 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1952 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1953 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1954 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1955 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1956 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1957 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1958 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1959 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1960 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1961 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1962 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1963 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1964 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1965 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1966 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1967 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1968 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1969 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1970 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1971 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1972 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1973 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1974 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1975 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1976 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1977 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1978 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1979 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1980 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1981 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1982 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1983 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1984 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1985 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1986 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1987 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1988 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1989 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1990 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1991 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1992 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1993 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1994 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1995 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1996 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1997 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1998 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 1999 \t| Loss = 0.2251949 \t| Accuracy = 0.9453125\n",
      "Iteration 2000 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2001 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2002 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2003 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2004 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2005 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2006 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2007 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2008 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2009 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2010 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2011 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2012 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2013 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2014 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2015 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2016 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2017 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2018 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2019 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2020 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2021 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2022 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2023 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2024 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2025 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2026 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2027 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2028 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2029 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2030 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2031 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2032 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2033 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2034 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2035 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2036 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2037 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2038 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2039 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2040 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2041 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2042 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2043 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2044 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2045 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2046 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2047 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2048 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2049 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2050 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2051 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2052 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2053 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2054 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2055 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2056 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2057 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2058 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2059 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2060 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2061 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2062 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2063 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2064 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2065 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2066 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2067 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2068 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2069 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2070 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2071 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2072 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2073 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2074 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2075 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2076 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2077 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2078 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2079 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2080 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2081 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2082 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2083 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2084 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2085 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2086 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2087 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2088 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2089 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2090 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2091 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2092 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2093 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2094 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2095 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2096 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2097 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2098 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2099 \t| Loss = 0.20679435 \t| Accuracy = 0.9296875\n",
      "Iteration 2100 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2101 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2102 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2103 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2104 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2105 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2106 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2107 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2108 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2109 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2110 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2111 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2112 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2113 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2114 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2115 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2116 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2117 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2118 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2119 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2120 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2121 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2122 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2123 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2124 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2125 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2126 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2127 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2128 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2129 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2130 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2131 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2132 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2133 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2134 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2135 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2136 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2137 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2138 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2139 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2140 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2141 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2142 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2143 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2144 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2145 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2146 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2147 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2148 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2149 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2150 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2151 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2152 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2153 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2154 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2155 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2156 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2157 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2158 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2159 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2160 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2161 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2162 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2163 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2164 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2165 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2166 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2167 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2168 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2169 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2170 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2171 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2172 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2173 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2174 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2175 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2176 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2177 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2178 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2179 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2180 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2181 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2182 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2183 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2184 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2185 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2186 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2187 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2188 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2189 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2190 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2191 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2192 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2193 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2194 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2195 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2196 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2197 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2198 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2199 \t| Loss = 0.1973782 \t| Accuracy = 0.953125\n",
      "Iteration 2200 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2201 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2202 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2203 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2204 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2205 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2206 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2207 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2208 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2209 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2210 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2211 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2212 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2213 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2214 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2215 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2216 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2217 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2218 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2219 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2220 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2221 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2222 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2223 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2224 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2225 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2226 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2227 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2228 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2229 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2230 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2231 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2232 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2233 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2234 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2235 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2236 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2237 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2238 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2239 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2240 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2241 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2242 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2243 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2244 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2245 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2246 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2247 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2248 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2249 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2250 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2251 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2252 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2253 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2254 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2255 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2256 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2257 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2258 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2259 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2260 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2261 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2262 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2263 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2264 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2265 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2266 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2267 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2268 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2269 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2270 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2271 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2272 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2273 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2274 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2275 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2276 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2277 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2278 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2279 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2280 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2281 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2282 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2283 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2284 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2285 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2286 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2287 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2288 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2289 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2290 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2291 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2292 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2293 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2294 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2295 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2296 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2297 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2298 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2299 \t| Loss = 0.3310544 \t| Accuracy = 0.921875\n",
      "Iteration 2300 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2301 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2302 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2303 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2304 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2305 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2306 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2307 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2308 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2309 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2310 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2311 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2312 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2313 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2314 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2315 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2316 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2317 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2318 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2319 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2320 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2321 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2322 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2323 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2324 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2325 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2326 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2327 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2328 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2329 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2330 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2331 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2332 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2333 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2334 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2335 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2336 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2337 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2338 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2339 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2340 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2341 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2342 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2343 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2344 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2345 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2346 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2347 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2348 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2349 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2350 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2351 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2352 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2353 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2354 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2355 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2356 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2357 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2358 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2359 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2360 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2361 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2362 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2363 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2364 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2365 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2366 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2367 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2368 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2369 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2370 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2371 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2372 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2373 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2374 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2375 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2376 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2377 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2378 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2379 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2380 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2381 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2382 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2383 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2384 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2385 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2386 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2387 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2388 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2389 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2390 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2391 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2392 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2393 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2394 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2395 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2396 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2397 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2398 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2399 \t| Loss = 0.3488496 \t| Accuracy = 0.9375\n",
      "Iteration 2400 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2401 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2402 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2403 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2404 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2405 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2406 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2407 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2408 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2409 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2410 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2411 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2412 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2413 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2414 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2415 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2416 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2417 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2418 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2419 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2420 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2421 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2422 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2423 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2424 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2425 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2426 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2427 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2428 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2429 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2430 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2431 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2432 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2433 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2434 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2435 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2436 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2437 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2438 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2439 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2440 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2441 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2442 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2443 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2444 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2445 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2446 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2447 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2448 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2449 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2450 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2451 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2452 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2453 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2454 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2455 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2456 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2457 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2458 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2459 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2460 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2461 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2462 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2463 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2464 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2465 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2466 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2467 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2468 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2469 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2470 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2471 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2472 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2473 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2474 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2475 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2476 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2477 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2478 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2479 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2480 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2481 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2482 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2483 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2484 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2485 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2486 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2487 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2488 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2489 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2490 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2491 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2492 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2493 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2494 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2495 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2496 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2497 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2498 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2499 \t| Loss = 0.20021337 \t| Accuracy = 0.9296875\n",
      "Iteration 2500 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2501 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2502 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2503 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2504 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2505 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2506 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2507 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2508 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2509 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2510 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2511 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2512 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2513 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2514 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2515 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2516 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2517 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2518 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2519 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2520 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2521 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2522 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2523 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2524 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2525 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2526 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2527 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2528 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2529 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2530 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2531 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2532 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2533 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2534 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2535 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2536 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2537 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2538 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2539 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2540 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2541 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2542 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2543 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2544 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2545 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2546 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2547 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2548 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2549 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2550 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2551 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2552 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2553 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2554 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2555 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2556 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2557 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2558 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2559 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2560 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2561 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2562 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2563 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2564 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2565 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2566 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2567 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2568 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2569 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2570 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2571 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2572 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2573 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2574 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2575 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2576 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2577 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2578 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2579 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2580 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2581 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2582 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2583 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2584 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2585 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2586 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2587 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2588 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2589 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2590 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2591 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2592 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2593 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2594 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2595 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2596 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2597 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2598 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2599 \t| Loss = 0.18975317 \t| Accuracy = 0.9375\n",
      "Iteration 2600 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2601 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2602 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2603 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2604 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2605 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2606 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2607 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2608 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2609 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2610 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2611 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2612 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2613 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2614 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2615 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2616 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2617 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2618 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2619 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2620 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2621 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2622 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2623 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2624 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2625 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2626 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2627 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2628 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2629 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2630 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2631 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2632 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2633 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2634 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2635 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2636 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2637 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2638 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2639 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2640 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2641 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2642 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2643 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2644 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2645 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2646 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2647 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2648 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2649 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2650 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2651 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2652 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2653 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2654 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2655 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2656 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2657 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2658 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2659 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2660 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2661 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2662 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2663 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2664 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2665 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2666 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2667 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2668 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2669 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2670 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2671 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2672 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2673 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2674 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2675 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2676 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2677 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2678 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2679 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2680 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2681 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2682 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2683 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2684 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2685 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2686 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2687 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2688 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2689 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2690 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2691 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2692 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2693 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2694 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2695 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2696 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2697 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2698 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2699 \t| Loss = 0.20005861 \t| Accuracy = 0.9453125\n",
      "Iteration 2700 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2701 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2702 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2703 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2704 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2705 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2706 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2707 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2708 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2709 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2710 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2711 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2712 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2713 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2714 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2715 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2716 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2717 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2718 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2719 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2720 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2721 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2722 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2723 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2724 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2725 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2726 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2727 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2728 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2729 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2730 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2731 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2732 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2733 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2734 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2735 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2736 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2737 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2738 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2739 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2740 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2741 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2742 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2743 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2744 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2745 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2746 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2747 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2748 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2749 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2750 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2751 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2752 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2753 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2754 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2755 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2756 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2757 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2758 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2759 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2760 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2761 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2762 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2763 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2764 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2765 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2766 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2767 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2768 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2769 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2770 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2771 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2772 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2773 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2774 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2775 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2776 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2777 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2778 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2779 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2780 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2781 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2782 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2783 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2784 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2785 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2786 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2787 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2788 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2789 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2790 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2791 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2792 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2793 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2794 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2795 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2796 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2797 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2798 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2799 \t| Loss = 0.1863504 \t| Accuracy = 0.9609375\n",
      "Iteration 2800 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2801 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2802 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2803 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2804 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2805 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2806 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2807 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2808 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2809 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2810 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2811 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2812 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2813 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2814 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2815 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2816 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2817 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2818 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2819 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2820 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2821 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2822 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2823 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2824 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2825 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2826 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2827 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2828 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2829 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2830 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2831 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2832 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2833 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2834 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2835 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2836 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2837 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2838 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2839 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2840 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2841 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2842 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2843 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2844 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2845 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2846 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2847 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2848 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2849 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2850 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2851 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2852 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2853 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2854 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2855 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2856 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2857 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2858 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2859 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2860 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2861 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2862 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2863 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2864 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2865 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2866 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2867 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2868 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2869 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2870 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2871 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2872 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2873 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2874 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2875 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2876 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2877 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2878 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2879 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2880 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2881 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2882 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2883 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2884 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2885 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2886 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2887 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2888 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2889 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2890 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2891 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2892 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2893 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2894 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2895 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2896 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2897 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2898 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2899 \t| Loss = 0.2278278 \t| Accuracy = 0.9296875\n",
      "Iteration 2900 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2901 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2902 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2903 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2904 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2905 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2906 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2907 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2908 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2909 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2910 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2911 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2912 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2913 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2914 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2915 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2916 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2917 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2918 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2919 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2920 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2921 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2922 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2923 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2924 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2925 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2926 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2927 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2928 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2929 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2930 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2931 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2932 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2933 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2934 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2935 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2936 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2937 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2938 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2939 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2940 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2941 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2942 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2943 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2944 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2945 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2946 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2947 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2948 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2949 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2950 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2951 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2952 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2953 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2954 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2955 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2956 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2957 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2958 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2959 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2960 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2961 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2962 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2963 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2964 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2965 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2966 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2967 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2968 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2969 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2970 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2971 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2972 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2973 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2974 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2975 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2976 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2977 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2978 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2979 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2980 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2981 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2982 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2983 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2984 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2985 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2986 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2987 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2988 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2989 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2990 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2991 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2992 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2993 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2994 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2995 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2996 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2997 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2998 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n",
      "Iteration 2999 \t| Loss = 0.35538787 \t| Accuracy = 0.8828125\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_iterations):\n",
    "    batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step, feed_dict={\n",
    "    X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "    if i % 100 == 0:\n",
    "           minibatch_loss, minibatch_accuracy = sess.run(\n",
    "           [cross_entropy, accuracy],\n",
    "           feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0}        )\n",
    "    print(\"Iteration\", str(i),\n",
    "             \"\\t| Loss =\",str(minibatch_loss),\"\\t| Accuracy =\",\n",
    "           str(minibatch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test set: 0.9229\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = sess.run(accuracy, feed_dict={X: mnist.test.images, Y:\n",
    "mnist.test.labels, keep_prob: 1.0})\n",
    "print(\"\\nAccuracy on test set:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.invert(Image.open(\"5.png\").convert('L')).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for test image: 2\n"
     ]
    }
   ],
   "source": [
    "prediction = sess.run(tf.argmax(output_layer, 1), feed_dict={X: [img]})\n",
    "print (\"Prediction for test image:\", np.squeeze(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
